<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Manisha Panchakam</title>
    <description>cached thoughts</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 02 Feb 2025 18:09:10 +0530</pubDate>
    <lastBuildDate>Sun, 02 Feb 2025 18:09:10 +0530</lastBuildDate>
    <generator>Jekyll v3.9.0</generator>
    
      <item>
        <title>Indian Philosophies as Reinforcement Learning</title>
        <description>&lt;p&gt;&lt;strong&gt;Indian Philosophies as Reinforcement Learning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Reinforcement Learning (RL) provides a powerful framework for understanding intelligence and decision-making. At its core, RL models an agent interacting with an environment, taking actions to maximize cumulative reward. This paradigm turns out to be surprisingly applicable to various domains, including, as I’ve been pondering lately, Indian philosophical systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The RL Setup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let’s start with a quick refresher on RL. The basic setup involves:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;An agent&lt;/li&gt;
  &lt;li&gt;An environment&lt;/li&gt;
  &lt;li&gt;A set of possible actions&lt;/li&gt;
  &lt;li&gt;State observations&lt;/li&gt;
  &lt;li&gt;A reward signal&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The agent’s goal is to learn a policy that maximizes expected cumulative reward over time. This framework is remarkably general and can model a wide range of situations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/agentinterface.png&quot; alt=&quot;*Agent Environment Interface*&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;The Agent-Environment Interface in Reinforcement Learning&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Indian Philosophy: The Big Picture&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Now, let’s turn to Indian philosophy. While diverse, many schools share some common themes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Atman: Individual consciousness&lt;/li&gt;
  &lt;li&gt;Brahman: Supreme or universal consciousness&lt;/li&gt;
  &lt;li&gt;Samsara: The phenomenal world of experience and rebirth&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The central question often revolves around the relationship between these entities. How does individual consciousness relate to the universal? What’s the nature of our experienced reality?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An RL Perspective on Advaita Vedanta&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let’s start with Advaita Vedanta, one of the most influential schools of Indian philosophy. In the RL framework, we might map it like this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Atman (individual consciousness) → Agent&lt;/li&gt;
  &lt;li&gt;Samsara (phenomenal world) → Environment&lt;/li&gt;
  &lt;li&gt;Brahman (supreme consciousness) → The “true” nature of reality&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/sankara.jpg&quot; alt=&quot;*Adi Sankara*&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Adi Shankara, the propounder of Advaita Vedanta&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The key insight of Advaita is that Atman and Brahman are ultimately identical. In RL terms, this is like saying the agent and the entirety of the system (agent + environment) are one and the same. The apparent duality – the sense of being a separate agent in an environment – is considered an illusion (maya). It’s as if the universal consciousness is playing a cosmic game of RL with itself, creating the appearance of separate agents and an environment.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Visistadvaita: Qualified Non-Dualism&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Moving on to Visistadvaita, proposed by Ramanuja, we can model it as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Atman (individual consciousness) → Agent&lt;/li&gt;
  &lt;li&gt;Samsara (phenomenal world) → Environment&lt;/li&gt;
  &lt;li&gt;Brahman (supreme consciousness) → A specific, named entity (e.g., Vishnu)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ramanuja.jpg&quot; alt=&quot;*Ramanujacharya*&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Ramanujacharya, the propounder of Visistadvaita&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this view, the multiplicity of agents and the environment occurs due to “ego” - a failure to cooperate with other agents while being misled by small rewards within the environment. It’s like an RL scenario where agents are optimizing for local rewards, missing the bigger picture of global optimization. The key difference from Advaita is that while Atman is part of Brahman, it maintains some level of distinctness. In RL terms, it’s as if the agents are sub-components of a larger system, each with their own local reward functions, but ultimately part of a greater whole.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Dvaita: Dualism&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Dvaita, proposed by Madhva, takes a different approach:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Atman (individual consciousness) → Distinct agent&lt;/li&gt;
  &lt;li&gt;Samsara (phenomenal world) → Distinct environment&lt;/li&gt;
  &lt;li&gt;Brahman (supreme consciousness) → Separate supreme agent creating the environment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/madhva.jpg&quot; alt=&quot;*Madhvacharya*&quot; /&gt; 
&lt;em&gt;Madhvacharya, the propounder of Dvaita&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this view, the agent, environment, and supreme agent are indeed separate. It’s akin to a multi-agent RL system where one “super-agent” (Brahman) creates and maintains the environment for other agents (Atman) to operate in. This perspective aligns well with hierarchical RL frameworks, where higher-level agents can shape the environment or reward structures for lower-level agents.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Buddhism: A Different Approach&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Buddhism, while not typically categorized with the above systems, offers an interesting contrast:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rejects the existence of a supreme agent (no Brahman)&lt;/li&gt;
  &lt;li&gt;Focuses on the agent’s experience and decision-making process&lt;/li&gt;
  &lt;li&gt;Posits that the optimal policy is to detach from the reward function itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/buddha.jpg&quot; alt=&quot;*Gautama Buddha*&quot; /&gt;
&lt;br /&gt;
&lt;em&gt;Gautama Buddha, the founder of Buddhism&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In RL terms, Buddhism suggests that the root of suffering (suboptimal outcomes) lies in the reward function itself. The path to enlightenment could be seen as learning to operate without being driven by the conventional reward signal. This is a fascinating inversion of the standard RL objective. Instead of maximizing cumulative reward, the goal becomes to transcend the very notion of reward-seeking behavior.&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Aug 2024 05:32:10 +0530</pubDate>
        <link>http://localhost:4000/2024/08/12/rlphilosphy/</link>
        <guid isPermaLink="true">http://localhost:4000/2024/08/12/rlphilosphy/</guid>
        
        
      </item>
    
  </channel>
</rss>
